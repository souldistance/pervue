server:
  port: 80
    #配置访问项目路径
    #servlet:
  #context-path: /bookdemo
  #解决中文乱码
  tomcat:
    uri-encoding: UTF-8

#spring
spring:
  #profiles:
  #active: hikaricp
  datasource:
    driver-class-name: com.mysql.cj.jdbc.Driver
    #连接类型 druid type: com.alibaba.druid.pool.DruidDataSource
    #c3p0 数据源 type: com.mchange.v2.c3p0.ComboPooledDataSource
    #DBCP 数据源 type: org.apache.commons.dbcp2.BasicDataSource
    #bonecp 数据源 type: com.jolbox.bonecp.BoneCPDataSource
    type: com.zaxxer.hikari.HikariDataSource
    url: jdbc:mysql://localhost:3306/kylin?useUnicode=true&useSSL=false&characterEncoding=utf8&serverTimezone=Hongkong
    username: root
    password: root
  #freemarker模板引擎
  freemarker:
    #加载的路径 默认路径classpath:/templates/
    template-loader-path: classpath:/templates/
    #模板加载的后缀 默认后缀 .ftlh
    suffix: .ftlh
    #页面加载缓存 默认false
    cache: false
  #设置开启热部署
  devtools:
    restart:
      enabled: true
  #kafka配置
  kafka:
    bootstrap-servers: 192.168.131.130:9092
    #=============== provider  =======================
    # 写入失败时，重试次数。当leader节点失效，一个repli节点会替代成为leader节点，此时可能出现写入失败，
    # 当retris为0时，produce不会重复。retirs重发，此时repli节点完全成为leader节点，不会产生消息丢失。
    producer:
      retries: 0
      # 每次批量发送消息的数量,produce积累到一定数据，一次发送
      batch-size: 16384
      # produce积累数据一次发送，缓存大小达到buffer.memory就发送数据
      buffer-memory: 33554432
      # 指定消息key和value的序列化方式
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.springframework.kafka.support.serializer.JsonSerializer

    #=============== consumer  =======================
    # 指定默认消费者group id --> 由于在kafka中，同一组中的consumer不会读取到同一个消息，依靠groud.id设置组名
    consumer:
      group-id: consumer_group
      # enable.auto.commit:true --> 设置自动提交offset
      enable-auto-commit: true
      #如果'enable.auto.commit'为true，则消费者偏移自动提交给Kafka的频率（以毫秒为单位），默认值为5000。
      auto-commit-interval: 1000
      # 指定消息key和消息体的反序列化方式
  #redis配置
  redis:
    ##连接的第几个数据库
    database: 0
    #连接主机的地址
    host: 127.0.0.1
    #redis的端口号
    port: 6379
  #缓存的类型，官方提供了很多，这里我们填写redis
  cache:
    type: redis
  #解决中文乱码
  http:
    encoding:
      charset: UTF-8
      enabled: true
      force: true
  servlet:
    #上传配置
    multipart:
      #单个文件上传的大小限制
      max-file-size: 10MB
      #一次请求限制大小
      max-request-size: 100MB
  mvc:
    # 静态文件请求匹配方式
    static-path-pattern: /**
  resources:
    # 修改默认的静态寻址资源目录 多个使用逗号分隔,下边的是默认值,除了/pic/
    static-locations: classpath:/META-INF/resources/,classpath:/resources/,classpath:/static/,classpath:/public/,classpath:/pic/


#mybatis
mybatis-plus:
  #加载mapper映射文件
  mapper-locations: classpath:mappers/*.xml
  #别名设置
  type-aliases-package: com.songyinglong.pervue.entity
  #配置type-enums-package只对注解方式的枚举处理能提前加载缓存 (暂不需要开启...)
  #typeEnumsPackage: com.songyinglong.bookdemo.entity
  global-config:
    #刷新mapper 调试神器
    refresh: true
    db-config:
      #数据库中的下划线转成驼峰标志 用于resultType自动映射
      column-underline: true
  #原生配置
  configuration:
    #数据库储存自定义数据（code,displayName）,使用注解@EnumValue标记数据库要存的值
    #default-enum-type-handler: com.baomidou.mybatisplus.extension.handlers.MybatisEnumTypeHandler
    #数据库存储枚举Name
    #default-enum-type-handler: org.apache.ibatis.type.EnumTypeHandler
    #数据库存储枚举对象下标 （ordinal）
    default-enum-type-handler: org.apache.ibatis.type.EnumOrdinalTypeHandler
    #日志输出
    log-impl: org.apache.ibatis.logging.stdout.StdOutImpl

    #日志配置
    #logging:
    #level:
    #root: warn
    #com.songyinglong.bookdemo: tracesha
    #pattern:
    #console: '%p%m%n'